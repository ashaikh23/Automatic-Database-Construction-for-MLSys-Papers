{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXnMtVx-ejEr",
        "outputId": "791f19b4-675d-4da7-e743-0421f872b89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ho\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Iuy7t6etnx",
        "outputId": "5f2f9492-1fae-4bc2-9ad4-bf1a6a82e11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ho\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pprint\n",
        "from difflib import SequenceMatcher\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "URL = 'https://api.semanticscholar.org/graph/v1/paper/'\n",
        "HEADERS = { 'x-api-key':  'XpAdCTxvUU2udInEBaKwa97vtVe4MvRO8rDESYWK' }\n",
        "CLUSTER_FIELDS = ','.join([\"title\", \"abstract\"])\n",
        "# DB_FIELDS = ','.join([\"title\", \"year\", \"authors\", \"citations.paperId\", \"citations.title\", \"references.paperId\", \"references.title\"])\n",
        "\n",
        "def str_sim(strA: str, strB: str) -> float:\n",
        "    return SequenceMatcher(None, strA, strB).ratio()\n",
        "\n",
        "def query_papers(query: str):\n",
        "    PARAMS = {\n",
        "        \"query\": query,\n",
        "        \"limit\": 5,\n",
        "        \"fields\": CLUSTER_FIELDS\n",
        "    }\n",
        "    response = requests.get(URL + \"search\", headers=HEADERS, params=PARAMS)\n",
        "\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        if \"data\" in data:\n",
        "            return data[\"data\"]\n",
        "        else:\n",
        "            print(\"No papers found for query:\", query)\n",
        "            return []  # Return an empty list if no data is found\n",
        "    else:\n",
        "        raise Exception(\"Error: \" + response.text)\n",
        "\n",
        "\n",
        "# # Documentation: https://api.semanticscholar.org/api-docs/#tag/Paper-Data/operation/get_graph_get_paper\n",
        "# def get_paper(paperID: str):\n",
        "#     PARAMS = {\n",
        "#         \"CLUSTER_FIELDS\": CLUSTER_FIELDS\n",
        "#     }\n",
        "#     response = requests.get(URL + paperID, headers=HEADERS, params=PARAMS)\n",
        "\n",
        "#     if response.ok:\n",
        "#         return response.json()\n",
        "#     else:\n",
        "#         raise Exception(\"Error: \" + response.text)\n",
        "\n",
        "def get_matching_paper(title: str):\n",
        "    data = query_papers(title)\n",
        "    target = max(data, key=lambda entry: str_sim(title, entry['title']))\n",
        "    return target\n",
        "\n",
        "def produce(csv_name):\n",
        "    df = pd.read_csv(csv_name)\n",
        "    titles = df['Title'].tolist()\n",
        "    i = 1\n",
        "    for title in titles:\n",
        "        data = get_matching_paper(title)\n",
        "        yield data['paperId'], data['title'], data['abstract']\n",
        "        if i % 50 == 0:\n",
        "            print('Finished', i)\n",
        "        time.sleep(0.5)\n",
        "        i += 1\n",
        "\n",
        "def query_papers(query: str):\n",
        "    PARAMS = {\n",
        "        \"query\": query,\n",
        "        \"limit\": 5,\n",
        "        \"fields\": CLUSTER_FIELDS\n",
        "    }\n",
        "    response = requests.get(URL + \"search\", headers=HEADERS, params=PARAMS)\n",
        "\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        print(data)  # Print the response to inspect its structure\n",
        "        return data[\"data\"]\n",
        "    else:\n",
        "        raise Exception(\"Error: \" + response.text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.DataFrame(produce(\"mlsys_papers.csv\"), columns=[\"ID\", \"Title\", \"Abstract\"])\n",
        "    df.to_csv(\"mlsys_cluster.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "9wBABfpee42S",
        "outputId": "58798e6b-5a3b-4dd8-e809-4d460512370f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total': 0, 'offset': 0}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a440add07884>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mlsys_papers.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Abstract\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mlsys_cluster.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_dataclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a440add07884>\u001b[0m in \u001b[0;36mproduce\u001b[0;34m(csv_name)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matching_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paperId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a440add07884>\u001b[0m in \u001b[0;36mget_matching_paper\u001b[0;34m(title)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_matching_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_papers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a440add07884>\u001b[0m in \u001b[0;36mquery_papers\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print the response to inspect its structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import requests\n",
        "\n",
        "S2_API_KEY = os.getenv('S2_API_KEY')\n",
        "result_limit = 10\n",
        "\n",
        "\n",
        "def main():\n",
        "    basis_paper = find_basis_paper()\n",
        "    find_recommendations(basis_paper)\n",
        "\n",
        "\n",
        "def find_basis_paper():\n",
        "    papers = None\n",
        "    while not papers:\n",
        "        query = input('Find papers about what: ')\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        rsp = requests.get('https://api.semanticscholar.org/graph/v1/paper/search',\n",
        "                           headers={'X-API-KEY': S2_API_KEY},\n",
        "                           params={'query': query, 'limit': result_limit, 'fields': 'title,url'})\n",
        "        rsp.raise_for_status()\n",
        "        results = rsp.json()\n",
        "        total = results[\"total\"]\n",
        "        if not total:\n",
        "            print('No matches found. Please try another query.')\n",
        "            continue\n",
        "\n",
        "        print(f'Found {total} results. Showing up to {result_limit}.')\n",
        "        papers = results['data']\n",
        "        print_papers(papers)\n",
        "\n",
        "    selection = ''\n",
        "    while not re.fullmatch('\\\\d+', selection):\n",
        "        selection = input('Select a paper # to base recommendations on: ')\n",
        "    return results['data'][int(selection)]\n",
        "\n",
        "\n",
        "def find_recommendations(paper):\n",
        "    print(f\"Up to {result_limit} recommendations based on: {paper['title']}\")\n",
        "    rsp = requests.get(f\"https://api.semanticscholar.org/recommendations/v1/papers/forpaper/{paper['paperId']}\",\n",
        "                       headers={'X-API-KEY': S2_API_KEY},\n",
        "                       params={'fields': 'title,url', 'limit': 10})\n",
        "    rsp.raise_for_status()\n",
        "    results = rsp.json()\n",
        "    print_papers(results['recommendedPapers'])\n",
        "\n",
        "\n",
        "def print_papers(papers):\n",
        "    for idx, paper in enumerate(papers):\n",
        "        print(f\"{idx}  {paper['title']} {paper['url']}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLoqqWbXkyaO",
        "outputId": "c64db6ec-70da-4c3f-8708-d3d6fb760c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Find papers about what: robots\n",
            "Found 755036 results. Showing up to 10.\n",
            "0  Design, fabrication and control of soft robots https://www.semanticscholar.org/paper/9ba6d7604f06479e64e292dd78d8a48c612dd374\n",
            "1  Real-Time Obstacle Avoidance for Manipulators and Mobile Robots https://www.semanticscholar.org/paper/c8a04d0cbb9f70e86800b11b594c9a05d7b6bac0\n",
            "2  Magnetic Soft Materials and Robots. https://www.semanticscholar.org/paper/7ef04bce51f857f6b156c158aa86499fa3c8dee5\n",
            "3  IEEE/RSJ International Conference on Intelligent Robots and Systems https://www.semanticscholar.org/paper/dda867de88aff74f70fb9b2de0387297183afea5\n",
            "4  Robots and Jobs: Evidence from US Labor Markets https://www.semanticscholar.org/paper/be9aa6c68d4df56a55444b15a83ff1e62c869bb5\n",
            "5  RMA: Rapid Motor Adaptation for Legged Robots https://www.semanticscholar.org/paper/1ca5ff6555d9fc634d3858d1fda9b3de2a91b13a\n",
            "6  Understanding anthropomorphism in service provision: a meta-analysis of physical robots, chatbots, and other AI https://www.semanticscholar.org/paper/0bb29f3e0b7151920795b6d3588084d13c33c672\n",
            "7  Learning agile and dynamic motor skills for legged robots https://www.semanticscholar.org/paper/bb0ee42d406f2361fee89cf1274073185a0e9eec\n",
            "8  Bettering operation of Robots by learning https://www.semanticscholar.org/paper/aa0203418db9f9800f59687e2cb2a58d7b12c97d\n",
            "9  Brave new world: service robots in the frontline https://www.semanticscholar.org/paper/608787bb357cd2dc5ff5dad44b3eaf7080fa9997\n",
            "Select a paper # to base recommendations on: 1\n",
            "Up to 10 recommendations based on: Real-Time Obstacle Avoidance for Manipulators and Mobile Robots\n",
            "0  Multi-robot consensus formation based on virtual spring obstacle avoidance https://www.semanticscholar.org/paper/724d49835eb323b0b21eea685b07e7719ade7dcc\n",
            "1  Control of a Wheeled Robot on a Plane with Obstacles https://www.semanticscholar.org/paper/58072dd6a319574f194169fb8c50896d2e24786c\n",
            "2  Obstacle Avoidance Strategy for a Novel Skiing Robot in Unknown Snow Environments https://www.semanticscholar.org/paper/bb667fd296d39e110a022627f45751f4a63a4549\n",
            "3  Flexible Path Planning of Mobile Robot for Avoiding the Dynamic Obstacles Using Fuzzy Controllers https://www.semanticscholar.org/paper/6686b6bf2720eb0f664549009737858f011a3215\n",
            "4  A Collision Cone Approach for Control Barrier Functions https://www.semanticscholar.org/paper/de15f67313a872f781063ffe529f5c37b3bfe51f\n",
            "5  Mobile Robot Obstacle Detection and Avoidance with NAV-YOLO https://www.semanticscholar.org/paper/a8d33333aed2e6eab31724d61e964a6e7cf92d3d\n",
            "6  Geometric Slosh-Free Tracking for Robotic Manipulators https://www.semanticscholar.org/paper/997102e19d5be2095485fcf9ed1ce9fdf93da98b\n",
            "7  Using a Robot for Indoor Navigation and Door Opening Control Based on Image Processing https://www.semanticscholar.org/paper/6d8bfddda1850476ff61236d1b8521a4eed7ea70\n",
            "8  Enhancing 2D Path Search and PID Control for Autonomous Mobile Robots: A* Algorithm Optimization and Hardware https://www.semanticscholar.org/paper/76046222155ecebdfaf6a22c139757ad4200d98d\n",
            "9  Unicycle Robot’s Navigation Control with Obstacle Avoidance and Asymptotic Stability https://www.semanticscholar.org/paper/4cd72cdf8917f6f3b8ef9049fa394204a5821623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "URL = 'https://api.semanticscholar.org/graph/v1/paper/'\n",
        "HEADERS = {'x-api-key': '5RTw6MHqO44aHnMCRyXsC4x3nsFp1ZP7a0eOK6ol'}\n",
        "CLUSTER_FIELDS = ','.join([\"title\", \"abstract\"])\n",
        "\n",
        "\n",
        "def str_sim(strA: str, strB: str) -> float:\n",
        "    return SequenceMatcher(None, strA, strB).ratio()\n",
        "\n",
        "\n",
        "def query_papers(query: str):\n",
        "    PARAMS = {\n",
        "        \"query\": query,\n",
        "        \"limit\": 1,  # Limit to 1 result as we are looking for a specific paper\n",
        "        \"fields\": CLUSTER_FIELDS\n",
        "    }\n",
        "    response = requests.get(URL + \"search\", headers=HEADERS, params=PARAMS)\n",
        "\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        return data.get(\"data\", [])  # Use .get() to avoid KeyError if data is empty\n",
        "    else:\n",
        "        raise Exception(\"Error: \" + response.text)\n",
        "\n",
        "\n",
        "def get_matching_paper(title: str):\n",
        "    data = query_papers(title)\n",
        "    if data:\n",
        "        return data[0]  # Return the first (and only) result if found\n",
        "    else:\n",
        "        print(\"No matching paper found for title:\", title)\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_paper_info(title: str):\n",
        "    paper = get_matching_paper(title)\n",
        "    if paper:\n",
        "        return paper['paperId'], paper['title'], paper['abstract']\n",
        "    else:\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def produce(csv_name):\n",
        "    df = pd.read_csv(csv_name)\n",
        "    for title in df['Title']:\n",
        "        paper_id, title, abstract = get_paper_info(title)\n",
        "        yield paper_id, title, abstract\n",
        "        time.sleep(0.5)  # Add a delay to avoid overwhelming the API\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.DataFrame(produce(\"mlsys_papers.csv\"), columns=[\"ID\", \"Title\", \"Abstract\"])\n",
        "    df.to_csv(\"mlsys_cluster.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igXnPVyBlYV3",
        "outputId": "426c9eee-8d9e-4693-dc10-0032e066dc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No matching paper found for title: Accelerating deep learning inference via freezing.\" 11th {USENIX} Workshop on Hot Topics in Cloud Computing\n",
            "No matching paper found for title: DeepCache: Principled cache for mobile deep vision.\" Proceedings of the 24th Annual International Conference on Mobile Computing and Networking\n",
            "No matching paper found for title: Swearingen, Thomas, et al. \"ATM: A distributed, collaborative, scalable system for automated machine learning.\n",
            "No matching paper found for title: Lianmin Zheng, UC Berkeley; Chengfan Jia, Minmin Sun, and Zhao Wu, Alibaba Inc.; Cody Hao Yu, Amazon Web Services, Inc; Ameer Haj-Ali, UC Berkeley; Yida Wang, Amazon Web Services, Inc; Jun Yang, Alibaba Inc.; Danyang Zhuo, Duke University and UC Berkeley; Koushik Sen, Joseph Gonzalez, and Ion Stoica, UC Berkeley\n",
            "No matching paper found for title: HiveD: Sharing a GPU Cluster for Deep Learning with Guarantees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#all values\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from difflib import SequenceMatcher\n",
        "#XpAdCTxvUU2udInEBaKwa97vtVe4MvRO8rDESYWK\n",
        "#5RTw6MHqO44aHnMCRyXsC4x3nsFp1ZP7a0eOK6ol\n",
        "URL = 'https://api.semanticscholar.org/graph/v1/paper/'\n",
        "HEADERS = {'x-api-key': 'XpAdCTxvUU2udInEBaKwa97vtVe4MvRO8rDESYWK'}\n",
        "CLUSTER_FIELDS = ','.join([\"title\", \"abstract\", \"url\", \"venue\", \"year\", \"authors\", \"citations\", \"references\"])\n",
        "\n",
        "def str_sim(strA: str, strB: str) -> float:\n",
        "    return SequenceMatcher(None, strA, strB).ratio()\n",
        "\n",
        "def query_papers(query: str):\n",
        "    PARAMS = {\n",
        "        \"query\": query,\n",
        "        \"limit\": 1,  # Limit to 1 result as we are looking for a specific paper\n",
        "        \"fields\": CLUSTER_FIELDS\n",
        "    }\n",
        "    response = requests.get(URL + \"search\", headers=HEADERS, params=PARAMS)\n",
        "\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        return data.get(\"data\", [])  # Use .get() to avoid KeyError if data is empty\n",
        "    else:\n",
        "        raise Exception(\"Error: \" + response.text)\n",
        "\n",
        "def get_matching_paper(title: str):\n",
        "    data = query_papers(title)\n",
        "    if data:\n",
        "        return data[0]  # Return the first (and only) result if found\n",
        "    else:\n",
        "        print(\"No matching paper found for title:\", title)\n",
        "        return None\n",
        "\n",
        "def get_paper_info(title: str):\n",
        "    paper = get_matching_paper(title)\n",
        "    if paper:\n",
        "        return {\n",
        "            'Paper ID': paper['paperId'],\n",
        "            'URL': paper['url'],\n",
        "            'Title': paper['title'],\n",
        "            'Venue': paper['venue'],\n",
        "            'Year': paper['year'],\n",
        "            'Authors': [{'Name': author['name'], 'Author ID': author['authorId']} for author in paper['authors']],\n",
        "            'Citations': [citation['paperId'] for citation in paper['citations']],\n",
        "            'References': [reference['paperId'] for reference in paper['references']],\n",
        "            'Abstract': paper['abstract']\n",
        "        }\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def produce(csv_name):\n",
        "    df = pd.read_csv(csv_name)\n",
        "    for title in df['Title']:\n",
        "        paper_info = get_paper_info(title)\n",
        "        if paper_info:\n",
        "            yield paper_info\n",
        "        else:\n",
        "            time.sleep(0.6)  # Add a delay to avoid overwhelming the API\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.DataFrame(produce(\"mlsys_papers.csv\"))\n",
        "    df.to_csv(\"mlsys_cluster.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "dWVC97tCqHjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fc8cda-5866-4f30-cc26-d20617693e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No matching paper found for title: Lianmin Zheng, UC Berkeley; Chengfan Jia, Minmin Sun, and Zhao Wu, Alibaba Inc.; Cody Hao Yu, Amazon Web Services, Inc; Ameer Haj-Ali, UC Berkeley; Yida Wang, Amazon Web Services, Inc; Jun Yang, Alibaba Inc.; Danyang Zhuo, Duke University and UC Berkeley; Koushik Sen, Joseph Gonzalez, and Ion Stoica, UC Berkeley\n",
            "No matching paper found for title: HiveD: Sharing a GPU Cluster for Deep Learning with Guarantees\n"
          ]
        }
      ]
    }
  ]
}